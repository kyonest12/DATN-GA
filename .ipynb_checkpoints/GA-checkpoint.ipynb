{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7aacc14-1c9d-4db7-911f-eb11110d729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quicksort(arr, compare):\n",
    "    if len(arr) <= 1:\n",
    "        return arr\n",
    "    pivot = arr[len(arr) // 2]\n",
    "    left = [x for x in arr if compare(x, pivot) == 1]\n",
    "    middle = [x for x in arr if compare(x, pivot) == 2]\n",
    "    right = [x for x in arr if compare(x, pivot) == 0]\n",
    "    return quicksort(left, compare) + middle + quicksort(right, compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18db0b90-cb14-4c2d-b11b-d7414de3a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e9dbd49-c4c2-47c8-966b-9384abe77018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def extractNumberFromString(string):\n",
    "    numbers = re.findall(r'\\d+', string)\n",
    "    if numbers:\n",
    "        return int(numbers[0])  \n",
    "\n",
    "class task:\n",
    "    def __init__(self, sources, destinations, dataSize):\n",
    "        self.sources = sources\n",
    "        self.destinations = destinations\n",
    "        self.dataSize = dataSize\n",
    "\n",
    "class processor:\n",
    "    def __init__(self, cu, cost):\n",
    "        self.cu = cu\n",
    "        self.cost = cost\n",
    "\n",
    "class workFlow:\n",
    "    def __init__(self, filePath, deadline):\n",
    "        self.numberOfTasks = extractNumberFromString(filePath)\n",
    "        self.tasks = [task([], [], 0)] * self.numberOfTasks\n",
    "        self.DAG = self.getDAGFromXml(filePath)\n",
    "        self.deadline = deadline\n",
    "        degree = self.getDegree()\n",
    "        self.inDegree = degree[0]\n",
    "        self.zeroInDegree = degree[1]\n",
    "       \n",
    "\n",
    "    def getDAGFromXml(self, filePath):\n",
    "        tree = ET.parse(filePath)\n",
    "        root = tree.getroot()\n",
    "        dx = {}\n",
    "        namespace = {'dax': 'http://pegasus.isi.edu/schema/DAX'}\n",
    "\n",
    "        DAG = [[0 for _ in range(self.numberOfTasks)] for _ in range(self.numberOfTasks)]\n",
    "        jobs = {}\n",
    "        inData = [[]] * self.numberOfTasks\n",
    "        outData = [[]] * self.numberOfTasks\n",
    "\n",
    "        tasks = []\n",
    "        for i in range(self.numberOfTasks):\n",
    "            tasks.append(task([], [], 0))\n",
    "        \n",
    "        for job in root.findall('.//dax:job', namespace):\n",
    "            job_id = extractNumberFromString(job.attrib['id'])\n",
    "            uses = job.findall('.uses', namespace)\n",
    "            inputs = []\n",
    "            outputs = []\n",
    "            dataSize = 0\n",
    "\n",
    "            for use in job.findall('.//dax:uses', namespace):\n",
    "                file = use.attrib['file']\n",
    "                link = use.attrib['link']\n",
    "                data = int(use.attrib['size'])\n",
    "                if data < 0:\n",
    "                    data = 0 - data\n",
    "                if file not in dx:\n",
    "                    dx[file] = [[], -1, data]\n",
    "                if link == 'input':\n",
    "                    dx[file][0].append(job_id)\n",
    "                elif link == 'output':\n",
    "                    dx[file][1] = job_id\n",
    "\n",
    "            #inData[job_id] = inputs\n",
    "            #outData[job_id] = outputs\n",
    "\n",
    "            #!__________________________________________________\n",
    "            tasks[job_id].dataSize = float(job.attrib['runtime'])\n",
    "        \n",
    "        for dependencies in root.findall('.//dax:child', namespace):\n",
    "            childId = extractNumberFromString(dependencies.attrib['ref'])\n",
    "            for parents in dependencies.findall('.//dax:parent', namespace):\n",
    "                parentId = extractNumberFromString(parents.attrib['ref'])\n",
    "                tasks[childId].sources.append(parentId)\n",
    "                tasks[parentId].destinations.append(childId)\n",
    "\n",
    "        for key in dx:\n",
    "            for i in range(len(dx[key][0])):\n",
    "                if dx[key][1] == -1:\n",
    "                    continue\n",
    "                DAG[dx[key][1]][dx[key][0][i]] = dx[key][2]\n",
    "        for i in range(self.numberOfTasks):\n",
    "            self.tasks[i] = tasks[i]\n",
    "        return DAG\n",
    "        \n",
    "    def getDegree(self):\n",
    "        inDegree = [0] * self.numberOfTasks\n",
    "        zeroInDegree = []\n",
    "        for i in range(0, self.numberOfTasks):\n",
    "            for j in range(0, self.numberOfTasks):\n",
    "                if self.DAG[i][j] != 0:\n",
    "                    inDegree[j] += 1\n",
    "        for i in range(0, self.numberOfTasks):\n",
    "            if inDegree[i] == 0:\n",
    "                zeroInDegree.append(i)\n",
    "        return (inDegree, zeroInDegree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "828990c1-6e61-4966-8014-7e9a8073c6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = 20*1024*1024\n",
    "\n",
    "numberOfProcessors = 9\n",
    "listProcessors = [\n",
    "    processor(1, 0.12),\n",
    "    processor(1.5, 0.195),\n",
    "    processor(2, 0.28),\n",
    "    processor(2.5, 0.375),\n",
    "    processor(3, 0.48),\n",
    "    processor(3.5, 0.595),\n",
    "    processor(4, 0.72),\n",
    "    processor(4.5, 0.855),\n",
    "    processor(5, 1)\n",
    "]\n",
    "\n",
    "class VM:\n",
    "    def __init__(self, typed, idd):\n",
    "        self.typed = typed\n",
    "        self.idd = idd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e9df4d7-d0e2-488b-b68a-a722a47ba4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isBetter(a, b):\n",
    "    \n",
    "    '''if a.fitness == b.fitness:\n",
    "        return 2\n",
    "    return a.fitness < b.fitness'''\n",
    "    \n",
    "    if a.completionTime == b.completionTime and a.cost == b.cost:\n",
    "        return 2\n",
    "    if a.completionTime <= deadline and b.completionTime <= deadline:\n",
    "        return a.cost < b.cost\n",
    "    if a.completionTime <= deadline and b.completionTime > deadline:\n",
    "        return 1\n",
    "    if a.completionTime > deadline and b.completionTime > deadline:\n",
    "        return a.completionTime < b.completionTime\n",
    "    if a.completionTime > deadline and b.completionTime <= deadline:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "005a13dd-22f8-4c1a-bd72-3f770ab26ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def localSearch(chromosome):\n",
    "    find = True\n",
    "    best = Chromosome([], [])\n",
    "    while find == True:\n",
    "        #print(chromosome.completionTime, chromosome.cost)\n",
    "        best.completionTime = 1e9\n",
    "        best.cost = 1e9\n",
    "        best.fitness = 1e9\n",
    "        find = False\n",
    "        FT = [0] * numberOfProcessors\n",
    "        FTofTasks = [0] * workflow.numberOfTasks\n",
    "        process = [0] * len(chromosome.tasks)\n",
    "        cost = 0\n",
    "        for i in range(len(chromosome.tasks)):      \n",
    "            process[chromosome.tasks[i]] = chromosome.processors[i]\n",
    "        for i in range(len(chromosome.processors)):\n",
    "            for j in range(numberOfProcessors):\n",
    "                newChromo = copy.deepcopy(chromosome)\n",
    "                newChromo.processors[i] = VM(j, 0)\n",
    "                newChromo.cal_fitness()\n",
    "                if isBetter(newChromo, chromosome) == 1:\n",
    "                    find = True\n",
    "                    if isBetter(newChromo, best):\n",
    "                        best = copy.deepcopy(newChromo)\n",
    "        \n",
    "        #Find best neighbors\n",
    "        if find == True:\n",
    "            chromosome = copy.deepcopy(best)\n",
    "            #print(chromosome.completionTime, chromosome.cost)\n",
    "            #print(\"___________________________________________\")\n",
    "    chromosome.isHillClimbing = True\n",
    "    return chromosome\n",
    "\n",
    "def localSearchAddVm(chromosome):\n",
    "    find = True\n",
    "    Neighbors = []\n",
    "    #print(chromosome.completionTime, chromosome.cost)\n",
    "    while find == True:\n",
    "        find = False\n",
    "        FTofTasks = [0] * numberOfTasks\n",
    "        processor = [0] * numberOfTasks\n",
    "        FT = np.zeros((numberOfProcessors, numberOfTasks))\n",
    "        for i in range(len(chromosome.tasks)):\n",
    "            processor[chromosome.tasks[i]] = chromosome.processors[i]\n",
    "                \n",
    "        for i in range(len(chromosome.tasks)):\n",
    "            task = chromosome.tasks[i]\n",
    "            prc = chromosome.processors[i].typed\n",
    "            idd = chromosome.processors[i].idd\n",
    "            DAT_processor = -1\n",
    "            for j in range(len(workflow.tasks[task].sources)):\n",
    "                parent = workflow.tasks[task].sources[j]\n",
    "                DAT_processor = max(DAT_processor, FTofTasks[parent] + ((DAG[parent][task] / network ) if diff(processor[task], processor[parent]) else 0.0))\n",
    "            if FT[prc][idd] > DAT_processor:\n",
    "                start = 0\n",
    "                while (1):\n",
    "                    if start >= numberOfTasks - 1:\n",
    "                        break\n",
    "                    if FT[prc][start] <= DAT_processor:\n",
    "                        new_chromo = copy.deepcopy(chromosome)\n",
    "                        new_chromo.processors[i] = VM(prc, start)\n",
    "                        new_chromo.cal_fitness()\n",
    "                        if isBetter(new_chromo, chromosome) == 1:\n",
    "                            Neighbors.append(new_chromo)\n",
    "                        break\n",
    "                    start += 1\n",
    "            #cal FT\n",
    "            DAT_processor = max(DAT_processor, FT[prc][idd])\n",
    "            for j in range(len(workflow.tasks[task].destinations)):\n",
    "                child = workflow.tasks[task].destinations[j]\n",
    "                FT[prc][idd] = max(FT[prc][idd], FTofTasks[task] + ((DAG[task][child] / network ) if diff(processor[task], processor[child]) else 0.0))\n",
    "            DAT_prcessor = max(DAT_processor, FT[prc][idd])\n",
    "            FTofTasks[task] = DAT_processor + computationTime[task][prc]\n",
    "            FT[prc][idd] = FTofTasks[task]\n",
    "            \n",
    "        for i in range(len(Neighbors)):\n",
    "            if isBetter(Neighbors[i], chromosome) == 1:\n",
    "                find = True\n",
    "                chromosome = Neighbors[i]\n",
    "    chromosome.isHillClimbing = True\n",
    "    #print(chromosome.completionTime, chromosome.cost)\n",
    "    #print(\"___________________________success__________________________________\")\n",
    "    return chromosome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62b1dbef-90d0-4a0a-80c8-a199015db367",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\W'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\W'\n",
      "C:\\Users\\lminh\\AppData\\Local\\Temp\\ipykernel_17360\\1140132508.py:1: SyntaxWarning: invalid escape sequence '\\W'\n",
      "  '''import time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'import time\\n\\nfilepath = \"D:\\\\WorkFlowTest\\\\dax\\\\CyberShake_50.xml\"\\nworkflow = workFlow(filepath, 67.8999)\\ncomputationTime = []\\nfor i in range(workflow.numberOfTasks):\\n    computationTime.append([]) \\nfor i in range(workflow.numberOfTasks):\\n    for j in range(numberOfProcessors):\\n        computationTime[i].append(workflow.tasks[i].dataSize / (listProcessors[j].cu))\\nnumberOfTasks = workflow.numberOfTasks\\nDAG = workflow.DAG\\ndeadline = workflow.deadline\\npopulationSize = 100\\nperRandom = 0.5\\nperHeuristic = 0.5\\nperElitics = 0.4\\nperHC = 0.1\\npenalty = 1\\np_c = 0.95\\np_m = 0.02\\nmaxGeneration = 400\\nthreshHold = 20\\nfor i in range(30):\\n    start_time = time.time()\\n    ga = GA(workflow, populationSize, perRandom, perHeuristic, perElitics, perHC, penalty, p_c, p_m, maxGeneration, threshHold)\\n    sol = ga.find_solution()\\n    end_time = time.time()\\n    print(sol.completionTime, sol.cost, ga.bestGene, end_time - start_time)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import time\n",
    "\n",
    "filepath = \"D:\\WorkFlowTest\\dax\\CyberShake_50.xml\"\n",
    "workflow = workFlow(filepath, 67.8999)\n",
    "computationTime = []\n",
    "for i in range(workflow.numberOfTasks):\n",
    "    computationTime.append([]) \n",
    "for i in range(workflow.numberOfTasks):\n",
    "    for j in range(numberOfProcessors):\n",
    "        computationTime[i].append(workflow.tasks[i].dataSize / (listProcessors[j].cu))\n",
    "numberOfTasks = workflow.numberOfTasks\n",
    "DAG = workflow.DAG\n",
    "deadline = workflow.deadline\n",
    "populationSize = 100\n",
    "perRandom = 0.5\n",
    "perHeuristic = 0.5\n",
    "perElitics = 0.4\n",
    "perHC = 0.1\n",
    "penalty = 1\n",
    "p_c = 0.95\n",
    "p_m = 0.02\n",
    "maxGeneration = 400\n",
    "threshHold = 20\n",
    "for i in range(30):\n",
    "    start_time = time.time()\n",
    "    ga = GA(workflow, populationSize, perRandom, perHeuristic, perElitics, perHC, penalty, p_c, p_m, maxGeneration, threshHold)\n",
    "    sol = ga.find_solution()\n",
    "    end_time = time.time()\n",
    "    print(sol.completionTime, sol.cost, ga.bestGene, end_time - start_time)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "271f2cbc-30f2-40ea-a5eb-8ac04db8282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def diff(a, b):\n",
    "    #return not ((a.typed == b.typed) and (a.idd == b.idd))\n",
    "    return not (a.typed == b.typed)\n",
    "\n",
    "class Chromosome:\n",
    "    def __init__(self, processors, tasks):\n",
    "        self.processors = processors\n",
    "        self.tasks = tasks\n",
    "        self.completionTime = 0\n",
    "        self.fitness = 0\n",
    "        self.cost = 0.0\n",
    "        self.isHillClimbing = False\n",
    "        #self.cal_fitness()\n",
    "\n",
    "    @staticmethod\n",
    "    def crossover(chromosome1, chromosome2, crossover_rate):\n",
    "    \n",
    "        numTasks = len(chromosome1.tasks)\n",
    "        Child1 = Chromosome([VM(0, 0)] * numTasks, [-1] * numTasks)\n",
    "        Child2 = Chromosome([VM(0, 0)] * numTasks, [-1] * numTasks)\n",
    "\n",
    "        if random.random() > crossover_rate:\n",
    "            return None\n",
    "\n",
    "        #get position to crossover\n",
    "        pos = random.randint(1, numTasks)\n",
    "        dxC1 = [False] * (numTasks + 1)\n",
    "        dxC2 = [False] * (numTasks + 1)\n",
    "        #take left part from parents\n",
    "        for i in range(pos):\n",
    "            Child1.tasks[i] = chromosome1.tasks[i]\n",
    "            Child1.processors[i] = chromosome1.processors[i]\n",
    "            dxC1[chromosome1.tasks[i]] = True\n",
    "            Child2.tasks[i] = chromosome2.tasks[i]\n",
    "            Child2.processors[i] = chromosome2.processors[i]\n",
    "            dxC2[chromosome2.tasks[i]] = True\n",
    "\n",
    "        #take right part from parents\n",
    "        ps = pos\n",
    "        for i in range(numTasks):\n",
    "            if dxC1[chromosome2.tasks[i]] == False:\n",
    "                Child1.processors[ps] = chromosome2.processors[i]\n",
    "                Child1.tasks[ps] = chromosome2.tasks[i]\n",
    "                dxC1[chromosome2.tasks[i]] = True\n",
    "                ps += 1\n",
    "        ps = pos\n",
    "        for i in range(numTasks):\n",
    "            if dxC2[chromosome1.tasks[i]] == False:\n",
    "                Child2.processors[ps] = chromosome1.processors[i]\n",
    "                Child2.tasks[ps] = chromosome1.tasks[i]\n",
    "                dxC2[chromosome1.tasks[i]] = True\n",
    "                ps += 1\n",
    "        \n",
    "        return Child1, Child2\n",
    "    \n",
    "    def mutate(self, mutation_rate):\n",
    "        mutated_processors = self.processors[:]  # Create a copy of distributing\n",
    "        \n",
    "        # Choose a random position to mutate\n",
    "        mutate_position = random.randint(0, len(mutated_processors) - 1)\n",
    "        \n",
    "        # Mutate the value at the chosen position based on the mutation rate\n",
    "        if random.random() < mutation_rate:\n",
    "            mutated_processors[mutate_position].typed = random.randint(0, numberOfProcessors - 1)\n",
    "            mutated_processors[mutate_position].idd = 0\n",
    "        \n",
    "        # Return a new Chromosome object with the mutated distributing and the original scheduling_parts\n",
    "        return Chromosome(mutated_processors, self.tasks)\n",
    "\n",
    "    def cal_fitness(self):\n",
    "        FTofTasks = [0] * numberOfTasks\n",
    "        processor = [0] * numberOfTasks\n",
    "        FT = np.zeros((numberOfProcessors, numberOfTasks))\n",
    "        endLeaseTime = np.zeros((numberOfProcessors, numberOfTasks))\n",
    "        startLeaseTime = array = np.full((numberOfProcessors, numberOfTasks), 1e9)\n",
    "        dx = {}\n",
    "\n",
    "        completionTime = 0.0\n",
    "        cost = 0.0\n",
    "        for i in range(len(self.tasks)):\n",
    "            processor[self.tasks[i]] = self.processors[i]\n",
    "            \n",
    "        for i in range(len(self.tasks)):\n",
    "            task = self.tasks[i]\n",
    "            prc = self.processors[i].typed\n",
    "            idd = self.processors[i].idd\n",
    "            dx[(prc, idd)] = True\n",
    "            DAT_processor = FT[prc][idd]\n",
    "            for j in range(len(workflow.tasks[task].sources)):\n",
    "                parent = workflow.tasks[task].sources[j]\n",
    "                DAT_processor = max(DAT_processor, FTofTasks[parent] + ((DAG[parent][task] / network ) if diff(processor[task], processor[parent]) else 0.0))\n",
    "            FTofTasks[task] = DAT_processor + computationTime[task][prc]\n",
    "            FT[prc][idd] = FTofTasks[task]\n",
    "            completionTime = max(completionTime, FTofTasks[task])\n",
    "    \n",
    "            endLeaseTime[prc][idd] = max(endLeaseTime[prc][idd], FTofTasks[task])\n",
    "            for j in range(len(workflow.tasks[task].destinations)):\n",
    "                child = workflow.tasks[task].destinations[j]\n",
    "                endLeaseTime[prc][idd] = max(endLeaseTime[prc][idd], FTofTasks[task] + ((DAG[task][child] / network ) if diff(processor[task], processor[child]) else 0.0))\n",
    "                FT[prc][idd] = max(FT[prc][idd], FTofTasks[task] + ((DAG[task][child] / network ) if diff(processor[task], processor[child]) else 0.0))\n",
    "                \n",
    "            startLeaseTime[prc][idd] = min(startLeaseTime[prc][idd], DAT_processor)\n",
    "            for j in range(len(workflow.tasks[task].sources)):\n",
    "                parent = workflow.tasks[task].sources[j]\n",
    "                startLeaseTime[prc][idd] = min(startLeaseTime[prc][idd], DAT_processor - ((DAG[parent][task] / network ) if diff(processor[task], processor[parent]) else 0.0))\n",
    "\n",
    "        for i in range(len(self.processors)):\n",
    "            dd = self.processors[i].idd\n",
    "            kieu = self.processors[i].typed\n",
    "            if (kieu, dd) in dx:\n",
    "                dx.pop((kieu, dd))\n",
    "                cost += (math.ceil((endLeaseTime[kieu][dd] - startLeaseTime[kieu][dd]) / 3600)) * listProcessors[kieu].cost\n",
    "        \n",
    "        self.cost = cost\n",
    "        self.completionTime = completionTime\n",
    "        self.fitness = cost\n",
    "        if completionTime > deadline:\n",
    "            self.fitness += penalty * (completionTime - deadline)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1135041-c830-40ff-b479-51db9a6471a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'filepath = \"C:/Users/lminh/OneDrive/Desktop/test_8.xml\"\\nworkflow = workFlow(filepath, 1000)\\ncomputationTime = []\\nfor i in range(workflow.numberOfTasks):\\n    computationTime.append([]) \\nfor i in range(workflow.numberOfTasks):\\n    for j in range(numberOfProcessors):\\n        computationTime[i].append(workflow.tasks[i].dataSize / (listProcessors[j].cu))\\nnumberOfTasks = workflow.numberOfTasks\\nDAG = workflow.DAG\\ndeadline = workflow.deadline\\nc = Chromosome([VM(8, 0), VM(7, 0), VM(8, 0), VM(8, 0), VM(8, 0)], (0, 2, 1, 3, 4))\\nc.cal_fitness()\\nprint(c.completionTime, c.cost)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''filepath = \"C:/Users/lminh/OneDrive/Desktop/test_8.xml\"\n",
    "workflow = workFlow(filepath, 1000)\n",
    "computationTime = []\n",
    "for i in range(workflow.numberOfTasks):\n",
    "    computationTime.append([]) \n",
    "for i in range(workflow.numberOfTasks):\n",
    "    for j in range(numberOfProcessors):\n",
    "        computationTime[i].append(workflow.tasks[i].dataSize / (listProcessors[j].cu))\n",
    "numberOfTasks = workflow.numberOfTasks\n",
    "DAG = workflow.DAG\n",
    "deadline = workflow.deadline\n",
    "c = Chromosome([VM(8, 0), VM(7, 0), VM(8, 0), VM(8, 0), VM(8, 0)], (0, 2, 1, 3, 4))\n",
    "c.cal_fitness()\n",
    "print(c.completionTime, c.cost)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d28e6b9b-d20c-4dfa-9092-10dd9f2ce883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tournamentSelection(tournament):\n",
    "    winner = Chromosome([0] * workflow.numberOfTasks, [0] * workflow.numberOfProcessors)\n",
    "    for i in range(len(tournament)):\n",
    "        if isBetter(tournament[i], winner) == 1:\n",
    "            winner = tournament[i]\n",
    "    return winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e079393-af13-426d-9d6e-393f1100d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectBest(population, size, percentage):\n",
    "    size = int(size * percentage)\n",
    "    sortarr = quicksort(population, isBetter)\n",
    "    newGen = []\n",
    "    for i in range(size):\n",
    "        newGen.append(sortarr[i])\n",
    "    return newGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1126716b-3cd2-464f-a7b4-6f14ad674421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseProcessor(typed, task):\n",
    "    if typed == 0:\n",
    "        return random.randint(0, numberOfProcessors - 1)\n",
    "    else:\n",
    "        total_time = sum(computationTime[task])\n",
    "        if total_time == 0:\n",
    "            total_time = 0.0000001\n",
    "        positions = []\n",
    "        for i, time in enumerate(computationTime[task]):\n",
    "            # Tính xác suất của mỗi vị trí dựa trên thời gian tính toán\n",
    "            probability = 1 - (time / total_time)\n",
    "            positions.extend([i] * int(probability * numberOfTasks))  # Nhân với 100 để tăng độ chính xác\n",
    "        # Chọn ngẫu nhiên một vị trí từ danh sách\n",
    "        random_position = random.choice(positions)\n",
    "        return random_position\n",
    "\n",
    "def createRandomChromosome(inDegree, zeroInDegree, typed):\n",
    "    inDegree_copy = inDegree[:]\n",
    "    zeroInDegree_copy = zeroInDegree[:]\n",
    "    chromosome = Chromosome([0] * numberOfTasks, [0] * numberOfTasks)\n",
    "    i = 0\n",
    "    while(len(zeroInDegree_copy) > 0):\n",
    "        index_task = random.randint(0, len(zeroInDegree_copy) - 1)\n",
    "        task = zeroInDegree_copy[index_task]\n",
    "        processor = chooseProcessor(typed, task)\n",
    "        chromosome.tasks[i] = task\n",
    "        chromosome.processors[i] = VM(processor, 0)\n",
    "        zeroInDegree_copy.pop(index_task)\n",
    "        for j in range(len(workflow.tasks[task].destinations)):\n",
    "            adj = workflow.tasks[task].destinations[j]\n",
    "            inDegree_copy[adj] -= 1\n",
    "            if inDegree_copy[adj] == 0:\n",
    "                zeroInDegree_copy.append(adj)\n",
    "        i += 1\n",
    "\n",
    "    #multi thread\n",
    "    chromosome.cal_fitness()\n",
    "    return chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9be48f4a-185a-4954-8f30-03c7af595820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateRandomPopulation(size, percentage, inDegree, zeroInDegree):\n",
    "    randomPopulation = []\n",
    "            \n",
    "    #generate Ramdom Select population\n",
    "    size = int(size * percentage)\n",
    "    #percentageOfRandom = 0.50\n",
    "    #percentageOfRandomBasedOnComputeTime = 0.25\n",
    "    randomType = 0\n",
    "    #basedOnComputeTime = 1\n",
    "    #sizeR = int(percentageOfRandom * size)\n",
    "    #sizeB = int(percentageOfRandomBasedOnComputeTime * size)\n",
    "    for i in range(size):\n",
    "        randomPopulation.append(createRandomChromosome(inDegree, zeroInDegree, randomType))\n",
    "    #for i in range(sizeB):\n",
    "        #randomPopulation.append(createRandomChromosome(inDegree, zeroInDegree, basedOnComputeTime))\n",
    "    return randomPopulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "143288c5-7ccf-4a21-85c6-c90cd4bb874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createHeuristicChromosome(inDegree, zeroInDegree):\n",
    "    inDegree_copy = inDegree[:]\n",
    "    zeroInDegree_copy = zeroInDegree[:]\n",
    "    chromosome = Chromosome([0] * numberOfTasks, [0] * numberOfTasks)\n",
    "    FT = [0] * numberOfProcessors\n",
    "    process = [0] * numberOfTasks\n",
    "    FTofTasks = [0] * numberOfTasks\n",
    "    i = 0\n",
    "    while(len(zeroInDegree_copy) > 0):\n",
    "        index_task = random.randint(0, len(zeroInDegree_copy) - 1)\n",
    "        task = zeroInDegree_copy[index_task]\n",
    "        #choose processor\n",
    "        minFT = min(FT)\n",
    "        FT = [x - minFT for x in FT]\n",
    "        FT_thu = {}\n",
    "        for j in range(len(FT)):\n",
    "            if FT[j] == 0:\n",
    "                FT_thu[j] = 0\n",
    "                for k in range(len(workflow.tasks[task].sources)):\n",
    "                    parentTask = workflow.tasks[task].sources[k]\n",
    "                    FT_thu[j] = max(FT_thu[j], max(FT[j], FTofTasks[parentTask] + (DAG[parentTask][task] if process[parentTask] != j else 0)))\n",
    "                FT_thu[j] += computationTime[task][j]\n",
    "        total_value = sum(FT_thu.values())\n",
    "        # Tính tỷ lệ xác suất cho mỗi phần tử\n",
    "        probabilities = [value / total_value for value in FT_thu.values()]\n",
    "        # Chọn ngẫu nhiên một phần tử dựa trên xác suất\n",
    "        chosen = random.choices(list(FT_thu.keys()), weights=probabilities, k=1)[0]\n",
    "        \n",
    "        chromosome.tasks[i] = task\n",
    "        chromosome.processors[i] = VM(chosen, 0)\n",
    "        process[task] = chosen\n",
    "        FT[chosen] = FT_thu[chosen]\n",
    "        FTofTasks[task] = FT_thu[chosen]\n",
    "\n",
    "        zeroInDegree_copy.pop(index_task)\n",
    "        for j in range(len(workflow.tasks[task].destinations)):\n",
    "            adj = workflow.tasks[task].destinations[j]\n",
    "            inDegree_copy[adj] -= 1\n",
    "            if inDegree_copy[adj] == 0:\n",
    "                zeroInDegree_copy.append(adj)\n",
    "        i += 1\n",
    "\n",
    "    #multi thread\n",
    "    chromosome.cal_fitness()\n",
    "    return chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59c68e51-eca4-40ee-b0ab-a18f8be770f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateHeuristicPopulation(size, percentage, inDegree, zeroInDegree):\n",
    "    heuristicPopulation = []\n",
    "    size = int(percentage * size)\n",
    "    for i in range(size):\n",
    "        chro = createHeuristicChromosome(inDegree, zeroInDegree)\n",
    "        #print(chro.processors, chro.tasks, \"cc\")\n",
    "        heuristicPopulation.append(chro)\n",
    "    return heuristicPopulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c857fe5-4312-4163-818b-90f21ec5508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GA:\n",
    "    def __init__(self, workFlow, populationSize, perRandom, perHeuristic, perElitics, perHC, penalty, p_c, p_m, maxGeneration, threshHold):\n",
    "        self.populationSize = populationSize\n",
    "        self.worfFlow = workFlow\n",
    "        self.penalty = penalty\n",
    "        self.p_c = p_c\n",
    "        self.p_m = p_m\n",
    "        self.maxGeneration = maxGeneration\n",
    "        self.threshHold = threshHold\n",
    "        self.perRandom = perRandom\n",
    "        self.perHeuristic = perHeuristic\n",
    "        self.perElitics = perElitics\n",
    "        self.perHC = perHC\n",
    "        self.bestGene = 0\n",
    "\n",
    "        self.population = generateRandomPopulation(populationSize, perRandom, workFlow.inDegree, workFlow.zeroInDegree) + generateHeuristicPopulation(populationSize, perHeuristic, workFlow.inDegree, workFlow.zeroInDegree) \n",
    "    \n",
    "    \n",
    "    def find_solution(self):\n",
    "        best = Chromosome([VM(0, 0)] * numberOfTasks, [0] * numberOfTasks)\n",
    "        best.completionTime = 1e8\n",
    "        best.cost = 1e8\n",
    "        best.fitness = 1e8\n",
    "        notImprove = 0\n",
    "        for gene in range(self.maxGeneration):\n",
    "            #print(gene)\n",
    "            '''print(len(self.population))\n",
    "            for j in range(len(self.population)):\n",
    "                #print(self.population[j].completionTime, self.population[j].cost)\n",
    "                for k in range(len(self.population[j].processors)):\n",
    "                    print(self.population[j].processors[k].typed, end = \" \")\n",
    "                print()\n",
    "            print(\"_______________________________________\")'''\n",
    "            nextGen = selectBest(self.population, self.populationSize, self.perElitics) #get parent population\n",
    "\n",
    "            '''print(len(nextGen))\n",
    "            for j in range(len(nextGen)):\n",
    "                print(nextGen[j].completionTime, nextGen[j].cost)\n",
    "            print(\"______________nextTo_________________________\")'''\n",
    "            \n",
    "            \n",
    "            while (len(nextGen) < self.populationSize):\n",
    "                parents = random.sample(self.population, 2)\n",
    "                child = Chromosome.crossover(parents[0], parents[1], p_c)\n",
    "                if child == None:\n",
    "                    continue\n",
    "                child0 = child[0].mutate(p_m)\n",
    "                child1 = child[1].mutate(p_m)\n",
    "\n",
    "                #multi thread\n",
    "                child0.cal_fitness()\n",
    "                child1.cal_fitness()\n",
    "                nextGen.append(child0)\n",
    "                nextGen.append(child1)\n",
    "\n",
    "            nextGen = quicksort(nextGen, isBetter)\n",
    "            total_elements = len(nextGen)\n",
    "            num_elements_to_select = int(self.perHC * total_elements)\n",
    "            # Tạo danh sách các chỉ mục có thể được chọn, với xác suất cao hơn ở đầu\n",
    "            indices_with_bias = list(range(num_elements_to_select))\n",
    "            ss = int(perHC * populationSize)\n",
    "            for _ in range(ss):\n",
    "                # Lấy ngẫu nhiên chỉ mục từ danh sách với xác suất cao hơn ở đầu\n",
    "                selected_index = random.choices(indices_with_bias, weights=[2 ** i for i in range(num_elements_to_select)], k=1)[0]\n",
    "                # Lấy phần tử tương ứng với chỉ mục đã chọn\n",
    "                if nextGen[selected_index].isHillClimbing:\n",
    "                    continue\n",
    "                else:\n",
    "                    nextGen[selected_index].isHillClimbing = True\n",
    "                    #print(nextGen[selected_index].completionTime, nextGen[selected_index].cost)\n",
    "                    nextGen[selected_index] = localSearch(nextGen[selected_index])\n",
    "                    nextGen[selected_index] = localSearchAddVm(nextGen[selected_index])\n",
    "                    #print(nextGen[selected_index].completionTime, nextGen[selected_index].cost)\n",
    "                    #print(\"_______________________________________________________________\")\n",
    "            nextGen = quicksort(nextGen, isBetter)\n",
    "            nn = 0\n",
    "            averageViolation = 0\n",
    "            for i in range(len(nextGen)):\n",
    "                if nextGen[i].completionTime > deadline:\n",
    "                    nn += 1\n",
    "                    averageViolation += nextGen[i].completionTime - deadline\n",
    "            if nn == 0:\n",
    "                averageViolation = 1\n",
    "            \n",
    "            if isBetter(nextGen[0], best) == 1:\n",
    "                self.bestGene = gene\n",
    "                notImprove = 0\n",
    "                best = nextGen[0]\n",
    "                penalty = nextGen[0].completionTime / averageViolation\n",
    "                self.population = nextGen\n",
    "            else:\n",
    "                notImprove += 1\n",
    "                penalty = nextGen[len(nextGen) - 1].completionTime / averageViolation\n",
    "                if notImprove >= self.threshHold:\n",
    "                    return best\n",
    "        return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "61924716-5dc3-45c7-a20a-f87e67f43115",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\W'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\W'\n",
      "C:\\Users\\lminh\\AppData\\Local\\Temp\\ipykernel_17360\\2305718162.py:1: SyntaxWarning: invalid escape sequence '\\W'\n",
      "  filepath = \"D:\\WorkFlowTest\\dax\\LIGO_30.xml\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'for i in range(30):\\n    ga = GA(workflow, populationSize, perRandom, perHeuristic, perElitics, perHC, penalty, p_c, p_m, maxGeneration, threshHold)\\n    sol = ga.find_solution()\\n    print(sol.completionTime, sol.cost, ga.bestGene)'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"D:\\WorkFlowTest\\dax\\LIGO_30.xml\"\n",
    "workflow = workFlow(filepath, 298.7861700000001)\n",
    "\n",
    "computationTime = []\n",
    "for i in range(workflow.numberOfTasks):\n",
    "    computationTime.append([]) \n",
    "for i in range(workflow.numberOfTasks):\n",
    "    for j in range(numberOfProcessors):\n",
    "        computationTime[i].append(workflow.tasks[i].dataSize / (listProcessors[j].cu))\n",
    "\n",
    "populationSize = 300\n",
    "perRandom = 0.5\n",
    "perHeuristic = 0.5\n",
    "perElitics = 0.4\n",
    "perHC = 0.1\n",
    "penalty = 1\n",
    "p_c = 0.95\n",
    "p_m = 0.02\n",
    "maxGeneration = 100\n",
    "threshHold = 40\n",
    "'''for i in range(30):\n",
    "    ga = GA(workflow, populationSize, perRandom, perHeuristic, perElitics, perHC, penalty, p_c, p_m, maxGeneration, threshHold)\n",
    "    sol = ga.find_solution()\n",
    "    print(sol.completionTime, sol.cost, ga.bestGene)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "919ecae6-f5b8-42b7-86d9-c37e6be11cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\W'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\W'\n",
      "C:\\Users\\lminh\\AppData\\Local\\Temp\\ipykernel_17360\\577090386.py:1: SyntaxWarning: invalid escape sequence '\\W'\n",
      "  filepath = \"D:\\WorkFlowTest\\dax\\CyberShake_30.xml\"\n"
     ]
    }
   ],
   "source": [
    "filepath = \"D:\\WorkFlowTest\\dax\\CyberShake_30.xml\"\n",
    "workflow = workFlow(filepath, 62)\n",
    "\n",
    "computationTime = []\n",
    "for i in range(workflow.numberOfTasks):\n",
    "    computationTime.append([]) \n",
    "for i in range(workflow.numberOfTasks):\n",
    "    for j in range(numberOfProcessors):\n",
    "        computationTime[i].append(workflow.tasks[i].dataSize / (listProcessors[j].cu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a713547-5937-46d9-94b8-3e264624609c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\lminh\\onedrive\\desktop\\datn\\ga\\geneticalgorithm\\.venv\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\lminh\\onedrive\\desktop\\datn\\ga\\geneticalgorithm\\.venv\\lib\\site-packages (from openpyxl) (1.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c536e0b-86b1-4b75-a61c-9433c7bb91d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________start__________________\n",
      "D:/WorkFlowTest/dax/CyberShake_30.xml 0.005\n",
      "61.878809999999994\n",
      "61.324820241928094 7.195\n",
      "60.31009163523477 4.305\n",
      "61.814536079679215 6.414999999999998\n",
      "61.23751865462651 7.7700000000000005\n",
      "61.79251725006104 4.145\n",
      "63.02299499257406 5.02\n",
      "62.19566165924072 5.38\n",
      "61.80037579748365 4.14\n",
      "62.775661659240725 8.09\n",
      "61.86037579748365 4.62\n",
      "62.29216165924072 7.234999999999999\n",
      "D:/WorkFlowTest/dax/CyberShake_50.xml 0.005\n",
      "67.8999\n",
      "67.73235972631545 10.975000000000003\n",
      "67.85813750409324 10.585\n",
      "70.30127159542508 11.7\n",
      "67.72451595124745 10.975\n",
      "68.16309180471633 11.695000000000002\n",
      "67.5958235154833 9.445\n",
      "67.85591600460477 10.03\n",
      "67.88426448822023 10.299999999999997\n",
      "67.79616048431396 8.924999999999999\n",
      "67.84979176945156 9.94\n",
      "66.89410922976901 11.875000000000002\n",
      "D:/WorkFlowTest/dax/CyberShake_100.xml 0.005\n",
      "80.95673000000001\n",
      "110.5715496635437 16.070000000000004\n",
      "110.36795851580302 14.150000000000002\n",
      "107.05194593484059 21.090000000000003\n",
      "99.74794338226319 17.61\n",
      "114.85846237182616 14.895000000000001\n",
      "108.74688070276048 16.235000000000003\n",
      "119.8274915652805 15.045000000000002\n",
      "111.26981957632397 13.55\n",
      "111.43224814775255 18.475\n",
      "110.40272933124359 16.630000000000003\n",
      "115.58797479901995 16.575000000000003\n",
      "/CyberShake 0.005 0.48484848484848486 300.9041666666667\n",
      "______________start__________________\n",
      "D:/WorkFlowTest/dax/Epigenomics_30.xml 0.005\n",
      "1207.1897000000001\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 67\u001b[0m\n\u001b[0;32m     65\u001b[0m numrun \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     66\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 67\u001b[0m ga \u001b[38;5;241m=\u001b[39m \u001b[43mGA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworkflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpopulationSize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperRandom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperHeuristic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperElitics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperHC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_m\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxGeneration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshHold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m sol \u001b[38;5;241m=\u001b[39m ga\u001b[38;5;241m.\u001b[39mfind_solution()\n\u001b[0;32m     69\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[1;32mIn[40], line 16\u001b[0m, in \u001b[0;36mGA.__init__\u001b[1;34m(self, workFlow, populationSize, perRandom, perHeuristic, perElitics, perHC, penalty, p_c, p_m, maxGeneration, threshHold)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperHC \u001b[38;5;241m=\u001b[39m perHC\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbestGene \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation \u001b[38;5;241m=\u001b[39m generateRandomPopulation(populationSize, perRandom, workFlow\u001b[38;5;241m.\u001b[39minDegree, workFlow\u001b[38;5;241m.\u001b[39mzeroInDegree) \u001b[38;5;241m+\u001b[39m \u001b[43mgenerateHeuristicPopulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopulationSize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperHeuristic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkFlow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minDegree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkFlow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeroInDegree\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m, in \u001b[0;36mgenerateHeuristicPopulation\u001b[1;34m(size, percentage, inDegree, zeroInDegree)\u001b[0m\n\u001b[0;32m      3\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(percentage \u001b[38;5;241m*\u001b[39m size)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(size):\n\u001b[1;32m----> 5\u001b[0m     chro \u001b[38;5;241m=\u001b[39m \u001b[43mcreateHeuristicChromosome\u001b[49m\u001b[43m(\u001b[49m\u001b[43minDegree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzeroInDegree\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m#print(chro.processors, chro.tasks, \"cc\")\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     heuristicPopulation\u001b[38;5;241m.\u001b[39mappend(chro)\n",
      "Cell \u001b[1;32mIn[15], line 25\u001b[0m, in \u001b[0;36mcreateHeuristicChromosome\u001b[1;34m(inDegree, zeroInDegree)\u001b[0m\n\u001b[0;32m     23\u001b[0m total_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(FT_thu\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Tính tỷ lệ xác suất cho mỗi phần tử\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m [\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtotal_value\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m FT_thu\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Chọn ngẫu nhiên một phần tử dựa trên xác suất\u001b[39;00m\n\u001b[0;32m     27\u001b[0m chosen \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoices(\u001b[38;5;28mlist\u001b[39m(FT_thu\u001b[38;5;241m.\u001b[39mkeys()), weights\u001b[38;5;241m=\u001b[39mprobabilities, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "sizesWorkflow = [\"30\", \"50\", \"100\"]\n",
    "nameWorkflow = [\"/CyberShake\", \"/Epigenomics\", \"/Inspiral\", \"/LIGO\", \"/Montage\"]\n",
    "sourceDAX = \"D:/WorkFlowTest/dax\"\n",
    "cheapScheduleCost = np.array([\n",
    "    [0.12, 0.12, 0.12],\n",
    "    [0.6, 1.44, 13.56],\n",
    "    [0.24, 0.48, 0.72],\n",
    "    [0.24, 0.48, 0.72],\n",
    "    [0.12, 0.12, 0.12]\n",
    "])\n",
    "fastScheduleMakespan = np.array([[58.367999999999995, 60.58, 65.20400000000001],\n",
    "    [1124.21, 1553.6480000000001, 5975.6500000000015],\n",
    "    [267.03600000000006, 282.16, 266.552],\n",
    "    [267.03600000000006, 282.16, 266.552],\n",
    "    [11.302, 14.152000000000001, 17.144000000000002]])\n",
    "cheapScheduleMakespan = np.array([[760.5299999999999, 1524.5600000000004, 3215.7499999999995],\n",
    "    [17720.15, 41401.780000000006, 403400.19999999995],\n",
    "    [6617.0700000000015, 11761.949999999999, 21023.960000000003],\n",
    "    [6617.0700000000015, 11761.949999999999, 21023.960000000003],\n",
    "    [227.74999999999997, 508.64000000000016, 1079.3400000000004]])\n",
    "\n",
    "result = np.random.randint(0, 100, size=(100, 100, 2))\n",
    "runtime = np.zeros((10, 10, 10))\n",
    "populationSize = 100\n",
    "perRandom = 0.5\n",
    "perHeuristic = 0.5\n",
    "perElitics = 0.4\n",
    "perHC = 0.1\n",
    "penalty = 1\n",
    "p_c = 0.95\n",
    "p_m = 0.02\n",
    "maxGeneration = 400\n",
    "threshHold = 20\n",
    "lmao = 0\n",
    "for factor in np.arange(0.005, 0.055, 0.005):\n",
    "    lmao += 1\n",
    "    factor = round(factor, 3)\n",
    "    for j in range(len(nameWorkflow)):\n",
    "        filename = sourceDAX  + nameWorkflow[j]\n",
    "        numrun = 0.0\n",
    "        success = 0.0\n",
    "        cost = 0.0\n",
    "        print(\"______________start__________________\")\n",
    "        for k in range(len(sizesWorkflow)):\n",
    "            filename1 = filename + \"_\" + sizesWorkflow[k] + \".xml\"\n",
    "            workflow = workFlow(filename1, 0)\n",
    "            computationTime = []\n",
    "            for i in range(workflow.numberOfTasks):\n",
    "                    computationTime.append([]) \n",
    "            for i in range(workflow.numberOfTasks):\n",
    "                for jj in range(numberOfProcessors):\n",
    "                    computationTime[i].append(workflow.tasks[i].dataSize / (listProcessors[jj].cu))\n",
    "            numberOfTasks = workflow.numberOfTasks\n",
    "            DAG = workflow.DAG\n",
    "            deadline = fastScheduleMakespan[j][k] + (cheapScheduleMakespan[j][k] - fastScheduleMakespan[j][k]) * factor\n",
    "            workflow.deadline = deadline\n",
    "            print(filename1, factor)\n",
    "            print(deadline)\n",
    "\n",
    "            aa = 0\n",
    "            timee = 0\n",
    "            for test in range(11):\n",
    "                numrun += 1\n",
    "                start_time = time.time()\n",
    "                ga = GA(workflow, populationSize, perRandom, perHeuristic, perElitics, perHC, penalty, p_c, p_m, maxGeneration, threshHold)\n",
    "                sol = ga.find_solution()\n",
    "                end_time = time.time()\n",
    "                timee += end_time - start_time\n",
    "                print(sol.completionTime, sol.cost)\n",
    "                if sol.completionTime <= deadline:\n",
    "                    success += 1\n",
    "                aa +=  sol.cost / cheapScheduleCost[j][k]\n",
    "            cost += aa / 10\n",
    "            timee /= 10\n",
    "            runtime[j][k][lmao] = timee\n",
    "        print(nameWorkflow[j], factor, success / numrun, cost)\n",
    "        result[j][lmao] = (success / numrun, cost) \n",
    "    print(sucess / numrun, cost)\n",
    "    print(\"_____________end_____________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c3eda7-5d51-4a79-bb76-727f4edc33b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7aa88d-c0db-487a-b698-0b2229bd8bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab461d5c-cba5-4728-ad3f-72633a16f72a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be078bb1-4e19-475b-a1b4-dfe960e03660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
